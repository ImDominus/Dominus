{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "from time import time\n",
    "from collections import deque\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST\n",
    "#http://yann.lecun.com/exdb/mnist/\n",
    "def unpickle_MNIST(image, label):\n",
    "    #Read Image data\n",
    "    image_set = open(image, 'rb')\n",
    "    magic_number = struct.unpack(\">i\", image_set.read(4))[0]\n",
    "    number_images = struct.unpack(\">i\", image_set.read(4))[0]\n",
    "    rows = struct.unpack(\">i\", image_set.read(4))[0]\n",
    "    cols = struct.unpack(\">i\", image_set.read(4))[0]\n",
    "    image_set_data = np.reshape(np.fromstring(image_set.read(), dtype = np.uint8), (number_images, rows * cols))\n",
    "    image_set.close()\n",
    "    #Read Label data\n",
    "    label_set = open(label, 'rb')\n",
    "    magic_number = struct.unpack(\">i\", label_set.read(4))[0]\n",
    "    number_of_items = struct.unpack(\">i\", label_set.read(4))[0]\n",
    "    label_set_data = np.reshape(np.fromstring(label_set.read(), dtype = np.uint8), (number_of_items))\n",
    "    label_set.close()    \n",
    "    return image_set_data.reshape(image_set_data.shape[0], 1, 28, 28), label_set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- all training_data\n",
    "    y -- all training_label\n",
    "    \n",
    "    Return:\n",
    "    X_train -- training_dataset\n",
    "    y_train -- training_labelset\n",
    "    X_cross -- cross_validation_dataset\n",
    "    y_cross -- cross_validation_labelset\n",
    "    \"\"\"\n",
    "    data_count = X.shape[0]\n",
    "    shuffle_order = np.arange(data_count)\n",
    "    np.random.shuffle(shuffle_order)\n",
    "    X_train, y_train = X[shuffle_order][:(4 * data_count) // 5], y[shuffle_order][:(4 * data_count) // 5]\n",
    "    X_cross, y_cross = X[shuffle_order][(4 * data_count) // 5:], y[shuffle_order][(4 * data_count) // 5:]\n",
    "    return X_train, y_train, X_cross, y_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "train_image_name = \"mnist\\\\train-images.idx3-ubyte\"\n",
    "train_label_name = \"mnist\\\\train-labels.idx1-ubyte\"\n",
    "test_image_name = \"mnist\\\\t10k-images.idx3-ubyte\"\n",
    "test_label_name = \"mnist\\\\t10k-labels.idx1-ubyte\"\n",
    "\n",
    "X, y = unpickle_MNIST(train_image_name, train_label_name)\n",
    "X_train, y_train, X_cross, y_cross = shuffle(X, y)\n",
    "X_test, y_test = unpickle_MNIST(test_image_name, test_label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of this picture is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHgiL8QFCEHwjq/wGyc/r0RWsNLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x202d45dd940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing MNIST\n",
    "X = X_train.reshape(48000, 28, 28)\n",
    "i = np.random.choice(range(len(X)))\n",
    "plt.imshow(X[i], interpolation = 'nearest')\n",
    "print(\"Number of this picture is\", y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "\n",
    "def MNIST_train(X, y, lambd = 0, epoch = 5, learning_rate = 0.01, test = False):\n",
    "    global count\n",
    "    np.random.seed(1)\n",
    "    fc_W = dict()\n",
    "    fc_b = dict()\n",
    "    fc_gamma = dict()\n",
    "    fc_beta = dict()\n",
    "    fc_mean = dict()\n",
    "    fc_std = dict()\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "    Convolution_layer = [(28 * 28, 9, 8), (28 * 28, 9 * 8, 4)]\n",
    "    FC_layer = [28 * 28 * 4, 128, 10]\n",
    "    order = [len(Convolution_layer), len(FC_layer) - 1]\n",
    "\n",
    "    # Set Convolution Layer\n",
    "    for i, v in enumerate(Convolution_layer):\n",
    "        W, gamma, beta, mean, std = \"CW\" + str(i), \"Cz\" + str(i + 1),\\\n",
    "                                    \"Cz\" + str(i + 1), \"Cz\" + str(i + 1), \"Cz\" + str(i + 1)\n",
    "        n_in, n_f_size, n_f_num = v\n",
    "        fc_W[W] = dict()\n",
    "        fc_W[W][0] = np.random.randn(n_f_size, n_f_num) / np.sqrt(n_f_size / 2)\n",
    "        fc_W[W][1], fc_W[W][2] = np.zeros(fc_W[W][0].shape), np.zeros(fc_W[W][0].shape)\n",
    "        fc_gamma[gamma] = dict()\n",
    "        fc_gamma[gamma][0] = np.random.randn(n_in, n_f_num)\n",
    "        fc_gamma[gamma][1], fc_gamma[gamma][2] = np.zeros(fc_gamma[gamma][0].shape), np.zeros(fc_gamma[gamma][0].shape)\n",
    "        fc_beta[beta] = dict()\n",
    "        fc_beta[beta][0] = np.random.randn(n_in, n_f_num)\n",
    "        fc_beta[beta][1], fc_beta[beta][2] = np.zeros(fc_beta[beta][0].shape), np.zeros(fc_beta[beta][0].shape)\n",
    "        fc_mean[mean] = np.zeros((n_in, n_f_num))\n",
    "        fc_std[std] = np.zeros((n_in, n_f_num))\n",
    "\n",
    "    # Set Fully Connected Area\n",
    "    for i in range(len(FC_layer) - 1):\n",
    "        W, b, gamma, beta, mean, std = \"W\" + str(i), \"b\" + str(i), \"z\" + str(i + 1),\\\n",
    "                                       \"z\" + str(i + 1), \"z\" + str(i + 1), \"z\" + str(i + 1)\n",
    "        n_in, n_out = FC_layer[i], FC_layer[i + 1]\n",
    "        fc_W[W] = dict()\n",
    "        fc_W[W][0] = np.random.randn(n_in, n_out) / np.sqrt(n_in / 2)\n",
    "        fc_W[W][1], fc_W[W][2] = np.zeros(fc_W[W][0].shape), np.zeros(fc_W[W][0].shape)\n",
    "        fc_b[b] = dict()\n",
    "        fc_b[b][0] = np.zeros(n_out)\n",
    "        fc_b[b][1], fc_b[b][2] = np.zeros(fc_b[b][0].shape), np.zeros(fc_b[b][0].shape)\n",
    "        fc_gamma[gamma] = dict()\n",
    "        fc_gamma[gamma][0] = np.random.randn(n_out)\n",
    "        fc_gamma[gamma][1], fc_gamma[gamma][2] = np.zeros(fc_gamma[gamma][0].shape), np.zeros(fc_gamma[gamma][0].shape)\n",
    "        fc_beta[beta] = dict()\n",
    "        fc_beta[beta][0] = np.random.randn(n_out)\n",
    "        fc_beta[beta][1], fc_beta[beta][2] = np.zeros(fc_beta[beta][0].shape), np.zeros(fc_beta[beta][0].shape)\n",
    "        fc_mean[mean] = np.zeros(n_out)\n",
    "        fc_std[std] = np.zeros(n_out)\n",
    "    training_cost = []\n",
    "    # Training Start\n",
    "    for epo in range(epoch):\n",
    "        for i in range(0, X_train.shape[0], 128):\n",
    "            X_mini = X_train[i:i + 128]\n",
    "            y_mini = y_train[i:i + 128]\n",
    "            if test == True:\n",
    "                numerical_check(order, X_mini, y_mini, fc_W, fc_b, fc_gamma, fc_beta, fc_mean, fc_std, lambd)\n",
    "            #forward\n",
    "            cache = forward(order, X_mini, fc_W, fc_b, fc_gamma, fc_beta, fc_mean, fc_std)\n",
    "            if (count - 1) % 100 == 0:\n",
    "                training_cost.append(nn_cost(y_mini, cache['x'][-1], fc_W, lambd))\n",
    "            #backward\n",
    "            backward(order, cache, fc_W, fc_b, fc_gamma, fc_beta, fc_mean, fc_std, y_mini, learning_rate, test, lambd)\n",
    "            if (count - 1) % 100 == 0:\n",
    "                print(count - 1, \"lambda =\", lambd, \", iteration finished, Cost =\", training_cost[-1])\n",
    "            count += 1\n",
    "            if count == 2:\n",
    "                test = False\n",
    "\n",
    "    parameters = [fc_W, fc_b, fc_gamma, fc_beta, fc_mean, fc_std]\n",
    "    count = 1\n",
    "    return training_cost, parameters, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(order, X_first, W, b, gamma, beta, mean, std):\n",
    "    cache = dict()\n",
    "    cache['x'] = [X_first]\n",
    "    cache['x_col'] = []\n",
    "    cache['z'] = []\n",
    "    cache['z_bar'] = []\n",
    "    cache['z_y'] = []\n",
    "    cache['z_mean'] = []\n",
    "    cache['z_std'] = []\n",
    "    # Convolution\n",
    "    for layer in range(order[0]):\n",
    "        keyW, keyz = \"CW\" + str(layer), \"Cz\" + str(layer + 1)\n",
    "        cache['x_col'].append(im2col(cache['x'][-1]))\n",
    "        # After Convolution\n",
    "        cache['z'].append(conv(cache['x_col'][-1], W[keyW][0]))\n",
    "        # Batch\n",
    "        z_bar, z_y, z_mean, z_std = nn_batch(cache['z'][-1], gamma[keyz][0], beta[keyz][0], mean[keyz], std[keyz])\n",
    "        cache['z_bar'].append(z_bar)\n",
    "        cache['z_y'].append(z_y)\n",
    "        cache['z_mean'].append(z_mean)\n",
    "        cache['z_std'].append(z_std)\n",
    "        if layer != order[0] - 1:\n",
    "            cache['x'].append(conv_leaky_relu(cache['z_y'][-1]))\n",
    "        else:\n",
    "            k = conv_leaky_relu(cache['z_y'][-1])\n",
    "            cache['x'].append(k.reshape((k.shape[0], k.shape[1] * k.shape[2] * k.shape[3])))\n",
    "    # Fully Connected Neural Network\n",
    "    for layer in range(order[1]):\n",
    "        keyW, keyb, keyz = \"W\" + str(layer), \"b\" + str(layer), \"z\" + str(layer + 1)\n",
    "        cache['z'].append(nn_fc(cache['x'][-1], W[keyW][0], b[keyb][0]))\n",
    "        #Batch\n",
    "        z_bar, z_y, z_mean, z_std = nn_batch(cache['z'][-1], gamma[keyz][0], beta[keyz][0], mean[keyz], std[keyz])\n",
    "        cache['z_bar'].append(z_bar)\n",
    "        cache['z_y'].append(z_y)\n",
    "        cache['z_mean'].append(z_mean)\n",
    "        cache['z_std'].append(z_std)\n",
    "        #softmax\n",
    "        if layer == order[1] - 1:\n",
    "            cache['x'].append(nn_softmax(cache['z_y'][-1]))\n",
    "        else:\n",
    "            cache['x'].append(nn_leaky_relu(cache['z_y'][-1]))\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(order, cache, W, b, gamma, beta, mean, std, y, learning_rate, test, lambd):\n",
    "    dy = cache['x'].pop()\n",
    "    #dy /= dy.shape[0]\n",
    "    compare = deque()\n",
    "    for layer in range(order[1] - 1, -1, -1):\n",
    "        keyW, keyb, keyz = \"W\" + str(layer), \"b\" + str(layer), \"z\" + str(layer + 1)\n",
    "        if layer == order[1] - 1:\n",
    "            cache['z_y'].pop()\n",
    "            dy[np.arange(y.shape[0]), y] -= 1\n",
    "            dy /= y.shape[0]\n",
    "        else:\n",
    "            dy[(cache['z_y'].pop()) < 0] *= 0.01\n",
    "        # batch\n",
    "        dy, dgamma, dbeta = nn_grad_batch(cache['z'].pop(), cache['z_bar'].pop(), dy, gamma[keyz][0], \\\n",
    "                                          cache['z_mean'].pop(), cache['z_std'].pop())\n",
    "        if test == True:\n",
    "            compare.append((keyz, \"beta\", dbeta[:3]))\n",
    "            compare.append((keyz, \"gamma\", dgamma[:3]))\n",
    "        update(beta[keyz][0], dbeta, beta[keyz][1], beta[keyz][2], learning_rate)\n",
    "        update(gamma[keyz][0], dgamma, gamma[keyz][1], gamma[keyz][2], learning_rate)\n",
    "        # FC\n",
    "        dW, db, dy = nn_grad(cache['x'].pop(), W[keyW][0], b[keyb][0], dy, lambd)\n",
    "        if test == True:\n",
    "            compare.append((keyb, db[:3]))\n",
    "            compare.append((keyW, dW[:3, :3]))\n",
    "        update(b[keyb][0], db, b[keyb][1], b[keyb][2], learning_rate)\n",
    "        update(W[keyW][0], dW, W[keyW][1], W[keyW][2], learning_rate)\n",
    "    # Convolution\n",
    "    dy = dy.reshape(dy.shape[0], 4, 28, 28)\n",
    "    for layer in range(order[0] - 1, -1, -1):\n",
    "        keyW, keyz = \"CW\" + str(layer), \"Cz\" + str(layer + 1)\n",
    "        # Leaky relu\n",
    "        dy = flatten(dy, (cache['z_y']).pop())\n",
    "        # batch\n",
    "        dy, dgamma, dbeta = nn_grad_batch(cache['z'].pop(), cache['z_bar'].pop(), dy, gamma[keyz][0], \\\n",
    "                                          cache['z_mean'].pop(), cache['z_std'].pop())\n",
    "        if test == True:\n",
    "            compare.append((keyz, \"beta\", dbeta[:3, :3]))\n",
    "            compare.append((keyz, \"gamma\", dgamma[:3, :3]))\n",
    "        update(beta[keyz][0], dbeta, beta[keyz][1], beta[keyz][2], learning_rate)\n",
    "        update(gamma[keyz][0], dgamma, gamma[keyz][1], gamma[keyz][2], learning_rate)\n",
    "        # Conv\n",
    "        dW, dy = nn_conv_grad(cache['x_col'].pop(), W[keyW][0], dy, lambd)\n",
    "        if test == True:\n",
    "            compare.append((keyW, dW[:3, :3]))\n",
    "        update(W[keyW][0], dW, W[keyW][1], W[keyW][2], learning_rate)\n",
    "        dy = col2im(dy, cache['x'].pop())\n",
    "    if test == True:\n",
    "        print(\"Derivation\")\n",
    "        while len(compare) > 0:\n",
    "            a = compare.pop()\n",
    "            print(a[:-1])\n",
    "            print(a[-1])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X):\n",
    "    temp = np.pad(X, ((0, 0), (0, 0), (1, 1), (1, 1)), 'constant', constant_values = ((0, 0), (0, 0), (0, 0), (0, 0)))\n",
    "    X_col = np.zeros((X.shape[0], X.shape[2] * X.shape[3], 9 * X.shape[1]))\n",
    "    for n in range(X.shape[0]):\n",
    "        count = 0\n",
    "        for i in range(X.shape[2]):\n",
    "            for j in range(X.shape[3]):\n",
    "                X_col[n, count] = temp[n, :, i:i + 3, j:j + 3].reshape(9 * X.shape[1])\n",
    "                count += 1\n",
    "    return X_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(X, W):\n",
    "    # X = N, 28 * 28, 9 * 8, W = 9 * 8, 4\n",
    "    # y = N, 28 * 28, 4\n",
    "    y = np.matmul(X, W)#.transpose(0, 2, 1).reshape((X.shape[0], W.shape[1], 28, 28)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_batch(z, z_gamma, z_beta, z_mean, z_std, epsilon = 0.000001):\n",
    "    mean = z.mean(axis = 0)\n",
    "    std = (z.var(axis = 0) + epsilon) ** (1 / 2)\n",
    "    z_mean *= 0.9\n",
    "    z_mean += 0.1 * mean\n",
    "    z_std *= 0.9\n",
    "    z_std += 0.1 * std\n",
    "    z_x_bar = (z - mean) / std\n",
    "    z_y = z_gamma * z_x_bar + z_beta\n",
    "    return z_x_bar, z_y, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_leaky_relu(X):\n",
    "    y = X.transpose(0, 2, 1).reshape(X.shape[0], X.shape[2], 28, 28)\n",
    "    y[y < 0] *= 0.01\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_fc(X, W, b):\n",
    "    return np.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_leaky_relu(X):\n",
    "    y = X.copy()\n",
    "    y[y < 0] *= 0.01\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_softmax(x):\n",
    "    y = np.exp(x)\n",
    "    y /= y.sum(axis = 1, keepdims = True)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost(y, y_hat, W, lambd):\n",
    "    cost = np.sum(-np.log(y_hat[np.arange(y_hat.shape[0]), y])) / y.shape[0]\n",
    "    for key in W:\n",
    "        cost += np.sum(W[key][0] ** 2) * (lambd / (2 * y.shape[0]))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_grad_batch(x, x_bar, dy, gamma, mean, std):\n",
    "    m = x.shape[0]\n",
    "    dx_bar = dy * gamma\n",
    "    dx = (1 / (m * std)) * (m * dx_bar - np.sum(dx_bar, axis=0) - x_bar * np.sum(dx_bar * x_bar, axis=0))\n",
    "    dgamma = np.sum(dy * x_bar, axis = 0)\n",
    "    dbeta = np.sum(dy, axis = 0)\n",
    "    return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_grad(x, W, b, dy, lambd):\n",
    "    dW = np.matmul(x.T, dy) + (lambd / x.shape[0]) * W\n",
    "    db = np.sum(dy, axis = 0)\n",
    "    dX = np.matmul(dy, W.T)\n",
    "    return dW, db, dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(dy, y):\n",
    "    dy = dy.reshape(y.shape[0], y.shape[2], y.shape[1]).transpose(0, 2, 1)\n",
    "    dy[y < 0] *= 0.01\n",
    "    return dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(X_col, X):\n",
    "    X_im = np.zeros((X.shape[0], X.shape[1], X.shape[2] + 2, X.shape[3] + 2))\n",
    "    for n in range(X_col.shape[0]):\n",
    "        a, b = 0, 0\n",
    "        for i in range(X_col.shape[1]):\n",
    "            X_im[n, :, a:a + 3, b:b + 3] += X_col[n, i].reshape(X.shape[1], 3, 3)\n",
    "            b += 1\n",
    "            if b + 3 > X_im.shape[3]:\n",
    "                a += 1\n",
    "                b = 0\n",
    "    return X_im[:, :, 1:-1, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_conv_grad(x, W, dy, lambd):\n",
    "    dW = np.sum(np.matmul(x.transpose(0, 2, 1), dy), axis = 0) + (lambd / x.shape[0]) * W\n",
    "    dX = np.matmul(dy, W.T)\n",
    "    return dW, dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(W, dW, Wm, Wv, alpha, beta1 = 0.9, beta2 = 0.999, epsilon = (10 ** (-8))):\n",
    "    global count\n",
    "    alpha *= (1 / 2) ** (count / 100)\n",
    "    Wm *= beta1\n",
    "    Wm += (1 - beta1) * dW\n",
    "    Wv *= beta2\n",
    "    Wv += (1 - beta2) * (dW ** 2)\n",
    "    W -= (alpha * Wm / (1 - (beta1 ** count))) / np.sqrt((Wv / (1 - (beta2 ** count))) + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_check(order, X_first, y, W, b, gamma, beta, mean, std, lambd, h = 0.00001):\n",
    "    print(\"Numerical\")\n",
    "    #Convolution\n",
    "    for layer in range(order[0]):\n",
    "        keyW, keyz = \"CW\" + str(layer), \"Cz\" + str(layer + 1)\n",
    "        W_test = np.zeros((3, 3))\n",
    "        gamma_test = np.zeros((3, 3))\n",
    "        beta_test = np.zeros((3, 3))\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                W[keyW][0][i][j] += h\n",
    "                cost1 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                W[keyW][0][i][j] -= 2 * h\n",
    "                cost2 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                W_test[i][j] = (cost1 - cost2) / (2 * h)\n",
    "                W[keyW][0][i][j] += h\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                gamma[keyz][0][i][j] += h\n",
    "                cost1 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                gamma[keyz][0][i][j] -= 2 * h\n",
    "                cost2 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                gamma_test[i][j] = (cost1 - cost2) / (2 * h)\n",
    "                gamma[keyz][0][i][j] += h\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                beta[keyz][0][i][j] += h\n",
    "                cost1 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                beta[keyz][0][i][j] -= 2 * h\n",
    "                cost2 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                beta_test[i][j] = (cost1 - cost2) / (2 * h)\n",
    "                beta[keyz][0][i][j] += h\n",
    "        print((keyW))\n",
    "        print(W_test)\n",
    "        print()\n",
    "        print((keyz, \"gamma\"))\n",
    "        print(gamma_test)\n",
    "        print()\n",
    "        print((keyz, \"beta\"))\n",
    "        print(beta_test)\n",
    "    #Batch\n",
    "    for layer in range(order[1]):\n",
    "        keyW, keyb, keyz = \"W\" + str(layer), \"b\" + str(layer), \"z\" + str(layer + 1)\n",
    "        W_test = np.zeros((3, 3))\n",
    "        b_test = np.zeros(3)\n",
    "        gamma_test = np.zeros(3)\n",
    "        beta_test = np.zeros(3)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                W[keyW][0][i][j] += h\n",
    "                cost1 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                W[keyW][0][i][j] -= 2 * h\n",
    "                cost2 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "                W_test[i][j] = (cost1 - cost2) / (2 * h)\n",
    "                W[keyW][0][i][j] += h\n",
    "        for i in range(3):\n",
    "            b[keyb][0][i] += h\n",
    "            cost1 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "            b[keyb][0][i] -= 2 * h\n",
    "            cost2 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "            b_test[i] = (cost1 - cost2) / (2 * h)\n",
    "            b[keyb][0][i] += h\n",
    "        for i in range(3):\n",
    "            gamma[keyz][0][i] += h\n",
    "            cost1 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "            gamma[keyz][0][i] -= 2 * h\n",
    "            cost2 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "            gamma_test[i] = (cost1 - cost2) / (2 * h)\n",
    "            gamma[keyz][0][i] += h\n",
    "        for i in range(3):\n",
    "            beta[keyz][0][i] += h\n",
    "            cost1 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "            beta[keyz][0][i] -= 2 * h\n",
    "            cost2 = numerical_forward(order, X_first, y, W, b, gamma, beta, lambd)\n",
    "            beta_test[i] = (cost1 - cost2) / (2 * h)\n",
    "            beta[keyz][0][i] += h\n",
    "        print((keyW))\n",
    "        print(W_test)\n",
    "        print()\n",
    "        print((keyb))\n",
    "        print(b_test)\n",
    "        print()\n",
    "        print((keyz, \"gamma\"))\n",
    "        print(gamma_test)\n",
    "        print()\n",
    "        print((keyz, \"beta\"))\n",
    "        print(beta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_forward(order, X_first, y, W, b, gamma, beta, lambd):\n",
    "    #Convolution\n",
    "    y_hat = X_first\n",
    "    for layer in range(order[0]):\n",
    "        keyW, keyz = \"CW\" + str(layer), \"Cz\" + str(layer + 1)\n",
    "        y_hat = im2col(y_hat)\n",
    "        # After Convolution\n",
    "        y_hat = conv(y_hat, W[keyW][0])\n",
    "        # Batch\n",
    "        y_hat = numerical_batch(y_hat, gamma[keyz][0], beta[keyz][0])\n",
    "        if layer != order[0] - 1:\n",
    "            y_hat = conv_leaky_relu(y_hat)\n",
    "        else:\n",
    "            k = conv_leaky_relu(y_hat)\n",
    "            y_hat = k.reshape(k.shape[0], k.shape[1] * k.shape[2] * k.shape[3])\n",
    "    #Batch\n",
    "    for layer in range(order[1]):\n",
    "        keyW, keyb, keyz = \"W\" + str(layer), \"b\" + str(layer), \"z\" + str(layer + 1)\n",
    "        y_hat = nn_fc(y_hat, W[keyW][0], b[keyb][0])\n",
    "        #Batch\n",
    "        y_hat = numerical_batch(y_hat, gamma[keyz][0], beta[keyz][0])\n",
    "        #softmax\n",
    "        if layer == order[1] - 1:\n",
    "            y_hat = nn_softmax(y_hat)\n",
    "        else:\n",
    "            y_hat = nn_leaky_relu(y_hat)\n",
    "    cost = nn_cost(y, y_hat, W, lambd)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_batch(z, z_gamma, z_beta, epsilon = 0.000001):\n",
    "    mean = z.mean(axis = 0)\n",
    "    std = (z.var(axis = 0) + epsilon) ** (1 / 2)\n",
    "    z_x_bar = (z - mean) / std\n",
    "    z_y = z_gamma * z_x_bar + z_beta\n",
    "    return z_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters, order):\n",
    "    y_hat = test_forward(X, y, parameters, order)\n",
    "    y_hat = np.argmax(y_hat, axis = 1)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, y, parameters, order):\n",
    "    y_hat = test_forward(X, y, parameters, order)\n",
    "    y_hat = np.argmax(y_hat, axis = 1)\n",
    "    return np.sum(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward(X, y, parameters, order):\n",
    "    y_hat = X\n",
    "    W, b, gamma, beta, mean, std = parameters\n",
    "    for layer in range(order[0]):\n",
    "        keyW, keyz = \"CW\" + str(layer), \"Cz\" + str(layer + 1)\n",
    "        y_hat = im2col(y_hat)\n",
    "        y_hat = conv(y_hat, W[keyW][0])\n",
    "        y_hat = test_batch(y_hat, mean[keyz], std[keyz], gamma[keyz][0], beta[keyz][0])\n",
    "        if layer != order[0] - 1:\n",
    "            y_hat = conv_leaky_relu(y_hat)\n",
    "        else:\n",
    "            k = conv_leaky_relu(y_hat)\n",
    "            y_hat = k.reshape(k.shape[0], k.shape[1] * k.shape[2] * k.shape[3])\n",
    "\n",
    "    for layer in range(order[1]):\n",
    "        keyW, keyb, keyz = \"W\" + str(layer), \"b\" + str(layer), \"z\" + str(layer + 1)\n",
    "        y_hat = nn_fc(y_hat, W[keyW][0], b[keyb][0])\n",
    "        #Batch\n",
    "        y_hat = test_batch(y_hat, mean[keyz], std[keyz], gamma[keyz][0], beta[keyz][0])\n",
    "        #softmax\n",
    "        if layer != order[1] - 1:\n",
    "            y_hat = nn_leaky_relu(y_hat)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(z, mean, std, z_gamma, z_beta):\n",
    "    z_x_bar = (z - mean) / std\n",
    "    z_y = z_gamma * z_x_bar + z_beta\n",
    "    return z_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lambda = 0 , iteration finished, Cost = 3.24343291555\n",
      "100 lambda = 0 , iteration finished, Cost = 0.453644580045\n",
      "200 lambda = 0 , iteration finished, Cost = 0.248252479304\n",
      "300 lambda = 0 , iteration finished, Cost = 0.302381816727\n",
      "400 lambda = 0 , iteration finished, Cost = 0.18103957602\n",
      "500 lambda = 0 , iteration finished, Cost = 0.221043365079\n",
      "600 lambda = 0 , iteration finished, Cost = 0.191100008028\n",
      "700 lambda = 0 , iteration finished, Cost = 0.236106619381\n",
      "800 lambda = 0 , iteration finished, Cost = 0.206147439049\n",
      "900 lambda = 0 , iteration finished, Cost = 0.167280261629\n",
      "1000 lambda = 0 , iteration finished, Cost = 0.159201493982\n",
      "1100 lambda = 0 , iteration finished, Cost = 0.198482433987\n",
      "1200 lambda = 0 , iteration finished, Cost = 0.211451571852\n",
      "1300 lambda = 0 , iteration finished, Cost = 0.142769553978\n",
      "1400 lambda = 0 , iteration finished, Cost = 0.223148547895\n",
      "1500 lambda = 0 , iteration finished, Cost = 0.190883383676\n",
      "1600 lambda = 0 , iteration finished, Cost = 0.169407688503\n",
      "1700 lambda = 0 , iteration finished, Cost = 0.139375404709\n",
      "1800 lambda = 0 , iteration finished, Cost = 0.225815559374\n"
     ]
    },
   ],
   "source": [
    "L2regul = [0, 0.01, 0.03, 0.1, 0.3, 1]\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_cross = []\n",
    "lambd_parameters = []\n",
    "\n",
    "for lamb in L2regul:\n",
    "    cost, parameters, order = MNIST_train(X_train, y_train, lambd = lamb)\n",
    "    lambd_parameters.append(parameters)\n",
    "    acc = 0\n",
    "    for i in range(0, X_train.shape[0], 128):\n",
    "        acc += accuracy(X_train[i:i + 128], y_train[i:i + 128], parameters, order)\n",
    "    accuracy_train.append(acc / X_train.shape[0] * 100)\n",
    "    acc = 0\n",
    "    for i in range(0, X_cross.shape[0], 128):\n",
    "        acc += accuracy(X_cross[i:i + 128], y_cross[i:i + 128], parameters, order)\n",
    "    accuracy_cross.append(acc / X_cross.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96.470833333333331, 96.595833333333331] [95.566666666666663, 95.766666666666666]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x202d4586400>,\n",
       "  <matplotlib.axis.XTick at 0x202d51e03c8>],\n",
       " <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZJ/j85K1xYAwtFpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x202d6a46ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(accuracy_train, accuracy_cross)\n",
    "\n",
    "plt.plot(range(len(L2regul[:2])), accuracy_train)\n",
    "plt.plot(range(len(L2regul[:2])), accuracy_cross)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.title(\"ERROR\")\n",
    "plt.xticks(range(len(L2regul[:2])), L2regul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 95.88 %\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range(0, X_test.shape[0], 512):\n",
    "    acc += accuracy(X_test[i:i + 512], y_test[i:i + 512], lambd_parameters[0], order)\n",
    "acc /= X_test.shape[0]\n",
    "\n",
    "print(\"Test accuracy is\", acc * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real class is 8\n",
      "predict = 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeCIvxAUIQfCOr/ASrt5xGAWNdlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x202d3f88d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.choice(range(len(X_test)))\n",
    "plt.imshow(X_test[i].reshape((28, 28)), interpolation='nearest')\n",
    "print(\"real class is\", Y[i])\n",
    "print(\"predict =\", predict(X_test[i:i + 1], y_test[i:i + 1], lambd_parameters[0], order)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
